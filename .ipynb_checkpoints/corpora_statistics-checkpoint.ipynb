{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpora Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set home directory path\n",
    "hdir = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = hdir + \"/Box/Notes/Digital_Humanities/Corpora/pickled_tokenized_cleaned_corpora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + \"/raw_tokens.pkl\", \"rb\") as f:\n",
    "    doc_toks, hist_toks, lit_toks, combined_toks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + \"/corpora.pkl\", \"rb\") as f:\n",
    "    unsorted_doc_toks,\\\n",
    "                indo_xml_toks, hyd_xml_toks, trans_xml_toks,\\\n",
    "                trans_nar_toks, indo_nar_toks,\\\n",
    "                trans_nar_ext_toks, indo_nar_ext_toks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + \"/meta_corpora.pkl\", \"rb\") as f:\n",
    "    comb_india_nar_toks, comb_trans_nar_toks, nar_corpus_toks, doc_corpus_toks,\\\n",
    "                combined_corpus_toks, mega_corpus_toks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indo_nar_toks['awrangabadi_gul-i_rana_ser794'][10:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Raw Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + \"/raw_tokens.pkl\", \"rb\") as f:\n",
    "    raw_doc_toks, raw_nar_toks, raw_lit_toks, raw_combo_toks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'سلمه'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word frequency:  39.81356877543997\n"
     ]
    }
   ],
   "source": [
    "combo_freq = nltk.FreqDist(hist_toks)\n",
    "\n",
    "av_freq = sum(combo_freq.values())/len(combo_freq)\n",
    "print (\"Average word frequency: \", av_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('جنابعالیحضرتم', 6),\n",
       " ('اجمعینتیمنا', 5),\n",
       " ('جنابعالیمولایم', 4),\n",
       " ('جنابعالیحضرت', 4),\n",
       " ('وزارتپناهان', 2),\n",
       " ('امانخانمرحوم', 2),\n",
       " ('متعالیدرجات', 2),\n",
       " ('ذاتعالیمولایم', 1),\n",
       " ('عالیحضرتمولایم', 1),\n",
       " ('خدمتکارانشان', 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_toks = [x for x in raw_doc_toks if len(x)>10]\n",
    "long_freq = nltk.FreqDist(long_toks)\n",
    "long_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persian Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ابوعبدالرحمان', 4),\n",
       " ('امیرالمویمنین', 3),\n",
       " ('گرانمایگانشان', 2),\n",
       " ('راکارهاساختست', 2),\n",
       " ('کجاپیشکارشبانان', 2),\n",
       " ('وزیرالوزراییست', 2),\n",
       " ('اعتمادالدولتش', 2),\n",
       " ('المستنصربالله', 2),\n",
       " ('نفدالصبرالتقی', 2),\n",
       " ('اعتبارالاعتبار', 2)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_toks = [x for x in lit_toks if len(x)>12]\n",
    "long_freq = nltk.FreqDist(long_toks)\n",
    "long_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('بعد', 'از'), 70),\n",
       " (('از', 'روی'), 45),\n",
       " (('است', 'که'), 37),\n",
       " (('از', 'ان'), 37),\n",
       " (('بوده', 'است'), 33),\n",
       " (('بنده', 'گی'), 32),\n",
       " (('بنده', 'نوازا'), 31),\n",
       " (('عرض', 'بنده'), 31),\n",
       " (('الله', 'تعالی'), 28),\n",
       " (('که', 'از'), 28)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = nltk.ngrams(doc_toks, 2)\n",
    "bi_freq = nltk.FreqDist(bigrams)\n",
    "bi_freq.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('دولت', 'آباد', 'صوبه', 'خجسته', 'بنیاد'), 17),\n",
       " (('سرکار', 'دولت', 'آباد', 'صوبه', 'خجسته'), 15),\n",
       " (('التقصیر', 'التقصیر', 'التقصیر', 'التقصیر', 'التقصیر'), 14),\n",
       " (('بذکره', 'الاعلی', 'ما', 'قول', 'ایمه'), 10),\n",
       " (('الاعلی', 'ما', 'قول', 'ایمه', 'الاسلام'), 10),\n",
       " (('ما', 'قول', 'ایمه', 'الاسلام', 'رضی'), 10),\n",
       " (('قول', 'ایمه', 'الاسلام', 'رضی', 'الله'), 10),\n",
       " (('ایمه', 'الاسلام', 'رضی', 'الله', 'تعالی'), 10)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muchos_grams = nltk.ngrams(doc_toks, 5)\n",
    "muchos_freq = nltk.FreqDist(muchos_grams)\n",
    "muchos_freq.most_common(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf = list(muchos_freq.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('بذکره', 'الاعلی', 'ما', 'قول', 'ایمه'), 10),\n",
       " (('الاعلی', 'ما', 'قول', 'ایمه', 'الاسلام'), 10),\n",
       " (('ما', 'قول', 'ایمه', 'الاسلام', 'رضی'), 10),\n",
       " (('قول', 'ایمه', 'الاسلام', 'رضی', 'الله'), 10),\n",
       " (('ایمه', 'الاسلام', 'رضی', 'الله', 'تعالی'), 10)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('و', 'بعد', 'از', 'ان', 'شروع'), 9),\n",
       " (('میکنند', 'و', 'بعد', 'از', 'ان'), 7),\n",
       " (('سند', 'از', 'دفتر', 'صدارت', 'العالیه'), 6),\n",
       " (('بخاری', 'بعد', 'از', 'ختم', 'کتب'), 5),\n",
       " (('از', 'دفتر', 'صدارت', 'العالیه', 'سرفرازی'), 5),\n",
       " (('از', 'روی', 'خواهش', 'ایلچی', 'مذکور'), 4),\n",
       " (('قراه', 'میکنند', 'و', 'بعد', 'از'), 4)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to review how to do list comprehension over the above kind of list.\n",
    "[(x,y) for (x,y) in lmf if \"از\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
